# Ã TÆ°á»Ÿng Sá»­ Dá»¥ng GraphCodeBERT Cho PhÃ¡t Hiá»‡n Lá»—i Báº£o Máº­t

## ğŸ“Š PhÃ¢n TÃ­ch Dataset Hiá»‡n CÃ³

### Cáº¥u trÃºc dá»¯ liá»‡u:
- **Vulnerable code**: `/output/` - JSON files vá»›i AST tá»« Joern
- **Safe code**: `/output_safe/` - JSON files vá»›i AST Ä‘Ã£ fix
- **Vulnerability types**: Buffer Overflow, Command Injection, Path Traversal, SQL Injection

### Äáº·c Ä‘iá»ƒm cá»§a JSON files:
```json
{
  "functions": [{
    "function": "ClassName.main",
    "AST": [
      {
        "id": "...",
        "label": "METHOD_PARAMETER_IN",
        "properties": {
          "NAME": "args",
          "CODE": "String[] args",
          "LINE_NUMBER": "5",
          "TYPE_FULL_NAME": "..."
        },
        "edges": [...]
      }
    ]
  }]
}
```

## ğŸ¯ 5 Ã TÆ°á»Ÿng ChÃ­nh

### 1ï¸âƒ£ Binary Classification (ÄÆ¡n Giáº£n Nháº¥t)

**Má»¥c tiÃªu**: PhÃ¢n loáº¡i code lÃ  Vulnerable (1) hoáº·c Safe (0)

**Pipeline**:
```
JSON â†’ Extract AST Graph â†’ GraphCodeBERT Encoding â†’ Binary Classifier â†’ Safe/Vulnerable
```

**Implementation Steps**:
1. Parse JSON files Ä‘á»ƒ extract graph structure
2. Convert graph thÃ nh format phÃ¹ há»£p vá»›i GraphCodeBERT
3. Fine-tune GraphCodeBERT vá»›i binary classification head
4. Training vá»›i labeled data (vulnerable=1, safe=0)

**Code Structure**:
```python
# Preprocessing
def parse_joern_json(json_file):
    # Extract nodes, edges, properties
    # Return graph representation
    pass

# Model
class VulnerabilityDetector(nn.Module):
    def __init__(self):
        self.graphcodebert = RobertaModel.from_pretrained("microsoft/graphcodebert-base")
        self.classifier = nn.Linear(768, 2)  # Binary classification
    
    def forward(self, code_inputs, graph_inputs):
        # Encode with GraphCodeBERT
        # Classify
        pass
```

**Æ¯u Ä‘iá»ƒm**:
- âœ… ÄÆ¡n giáº£n, dá»… implement
- âœ… PhÃ¹ há»£p vá»›i dataset cÃ³ cáº·p vulnerable/safe
- âœ… Baseline tá»‘t Ä‘á»ƒ so sÃ¡nh

**NhÆ°á»£c Ä‘iá»ƒm**:
- âŒ KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c loáº¡i lá»—i
- âŒ KhÃ´ng táº­n dá»¥ng háº¿t thÃ´ng tin vá» fix

---

### 2ï¸âƒ£ Multi-Class Classification (PhÃ¢n Loáº¡i Chi Tiáº¿t)

**Má»¥c tiÃªu**: PhÃ¢n loáº¡i code theo 5 classes

**Classes**:
- 0: Safe Code
- 1: Buffer Overflow
- 2: Command Injection
- 3: Path Traversal
- 4: SQL Injection

**Pipeline**:
```
JSON â†’ AST Graph â†’ GraphCodeBERT â†’ Multi-Class Classifier â†’ Vulnerability Type
```

**Dataset Distribution** (cáº§n kiá»ƒm tra):
```python
# Count files in each category
categories = {
    'Buffer_Overflow': len(glob('output/Buffer_Overflow/*.json')),
    'Command_Injection': len(glob('output/Command_Injection/*.json')),
    'Path_Traversal': len(glob('output/Path_Traversal/*.json')),
    'SQL_Injection': len(glob('output/SQL_Injection/*.json')),
    'Safe': total_safe_files
}
```

**Model**:
```python
class MultiClassVulnerabilityDetector(nn.Module):
    def __init__(self, num_classes=5):
        self.graphcodebert = RobertaModel.from_pretrained("microsoft/graphcodebert-base")
        self.classifier = nn.Linear(768, num_classes)
```

**Æ¯u Ä‘iá»ƒm**:
- âœ… PhÃ¡t hiá»‡n Ä‘Æ°á»£c loáº¡i lá»—i cá»¥ thá»ƒ
- âœ… Há»¯u Ã­ch cho viá»‡c suggest fix
- âœ… Táº­n dá»¥ng 4 loáº¡i lá»—i trong dataset

**NhÆ°á»£c Ä‘iá»ƒm**:
- âŒ Cáº§n balance dataset (cÃ³ thá»ƒ má»™t sá»‘ loáº¡i lá»—i Ã­t hÆ¡n)
- âŒ Phá»©c táº¡p hÆ¡n binary classification

---

### 3ï¸âƒ£ Contrastive Learning (Há»c Tá»« Cáº·p Code)

**Má»¥c tiÃªu**: Há»c representation sao cho vulnerable vÃ  fixed version gáº§n nhau trong embedding space

**Approach**:
```
Positive pairs: (vulnerable_code, safe_fix) - same functionality
Negative pairs: different functionalities
```

**Architecture**:
```
                    â”Œâ”€â†’ Vulnerable Code â†’ GraphCodeBERT â†’ Embedding_v
Input Pair â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â””â”€â†’ Safe Fix Code â†’ GraphCodeBERT â†’ Embedding_s

Loss = Contrastive Loss(Embedding_v, Embedding_s)
```

**Loss Functions**:
1. **Triplet Loss**:
   - Anchor: Vulnerable code
   - Positive: Its safe fix
   - Negative: Different vulnerability
   
2. **NT-Xent Loss** (SimCLR style):
   ```python
   def contrastive_loss(z_v, z_s, temperature=0.07):
       similarity = cosine_similarity(z_v, z_s) / temperature
       return -log(exp(similarity) / sum(exp(all_similarities)))
   ```

**Training Strategy**:
```python
for vulnerable_file, safe_file in paired_dataset:
    emb_v = model(vulnerable_code)
    emb_s = model(safe_code)
    
    # Pull together (positive pair)
    positive_loss = distance(emb_v, emb_s)
    
    # Push away (negative pairs)
    negative_loss = -distance(emb_v, random_other_code)
    
    total_loss = positive_loss + negative_loss
```

**Use Cases**:
1. **Similarity Search**: TÃ¬m code tÆ°Æ¡ng tá»± Ä‘á»ƒ suggest fix
2. **Clustering**: NhÃ³m cÃ¡c lá»—i tÆ°Æ¡ng tá»± nhau
3. **Transfer Learning**: Pre-train rá»“i fine-tune cho classification

**Æ¯u Ä‘iá»ƒm**:
- âœ… Há»c Ä‘Æ°á»£c má»‘i quan há»‡ vulnerable-safe
- âœ… CÃ³ thá»ƒ suggest fix dá»±a trÃªn similarity
- âœ… Robust vá»›i unseen vulnerability types

---

### 4ï¸âƒ£ Graph Neural Network Approach (Táº­n Dá»¥ng AST)

**Äáº·c Ä‘iá»ƒm data tá»« Joern**:
```json
{
  "id": "111669149696",
  "label": "METHOD_PARAMETER_IN",
  "properties": {
    "NAME": "args",
    "CODE": "String[] args",
    "LINE_NUMBER": "5",
    "TYPE_FULL_NAME": "<unresolvedNamespace>.String[]"
  },
  "edges": [
    {"type": "AST", "out": "107374182400"},
    {"type": "REACHING_DEF", "out": "..."}
  ]
}
```

**Graph Features**:
1. **Node Features**:
   - Label (METHOD_PARAMETER_IN, CALL, IDENTIFIER, etc.)
   - Code snippet
   - Line number
   - Type information

2. **Edge Types**:
   - AST (Abstract Syntax Tree)
   - CFG (Control Flow)
   - REACHING_DEF (Data flow)
   - EVAL_TYPE (Type information)

**Model Architecture**:
```
Graph Structure 
    â†“
GraphCodeBERT (encode nodes with code context)
    â†“
Graph Attention Networks (propagate information)
    â†“
Graph Pooling (aggregate node embeddings)
    â†“
Classification
```

**Implementation**:
```python
class GraphVulnerabilityDetector(nn.Module):
    def __init__(self):
        # Encode each node's code
        self.code_encoder = RobertaModel.from_pretrained("microsoft/graphcodebert-base")
        
        # Graph layers to propagate information
        self.gat1 = GATConv(768, 256, heads=8)
        self.gat2 = GATConv(256*8, 128, heads=4)
        
        # Pooling
        self.pool = global_mean_pool
        
        # Classifier
        self.classifier = nn.Linear(128*4, num_classes)
    
    def forward(self, node_codes, edge_index, edge_types):
        # Encode node codes
        node_embeddings = [self.code_encoder(code).last_hidden_state[:, 0] 
                          for code in node_codes]
        
        # GNN propagation
        x = self.gat1(node_embeddings, edge_index)
        x = F.relu(x)
        x = self.gat2(x, edge_index)
        
        # Pool to graph-level
        graph_embedding = self.pool(x, batch)
        
        # Classify
        return self.classifier(graph_embedding)
```

**Táº­n dá»¥ng edge types**:
```python
# Heterogeneous graph with different edge types
class HeteroGraphModel(nn.Module):
    def __init__(self):
        self.ast_conv = GATConv(768, 256)
        self.cfg_conv = GATConv(768, 256)
        self.data_flow_conv = GATConv(768, 256)
        
    def forward(self, x, edge_dict):
        # Different processing for different edge types
        ast_out = self.ast_conv(x, edge_dict['AST'])
        cfg_out = self.cfg_conv(x, edge_dict['CFG'])
        df_out = self.data_flow_conv(x, edge_dict['REACHING_DEF'])
        
        # Combine
        return ast_out + cfg_out + df_out
```

**Æ¯u Ä‘iá»ƒm**:
- âœ… Táº­n dá»¥ng Ä‘áº§y Ä‘á»§ cáº¥u trÃºc graph tá»« Joern
- âœ… Capture Ä‘Æ°á»£c control flow vÃ  data flow
- âœ… PhÃ¹ há»£p vá»›i code analysis

**NhÆ°á»£c Ä‘iá»ƒm**:
- âŒ Phá»©c táº¡p hÆ¡n, cáº§n nhiá»u tÃ i nguyÃªn
- âŒ KhÃ³ debug

---

### 5ï¸âƒ£ Hierarchical Classification (PhÃ¢n Cáº¥p)

**Motivation**: Má»™t sá»‘ lá»—i dá»… phÃ¡t hiá»‡n hÆ¡n, má»™t sá»‘ khÃ³ hÆ¡n

**Architecture**:
```
Level 1: Safe vs Vulnerable (easier)
    â†“
Level 2: Vulnerability Type Classification (harder)
    â”œâ”€â†’ Buffer Overflow
    â”œâ”€â†’ Command Injection
    â”œâ”€â†’ Path Traversal
    â””â”€â†’ SQL Injection
```

**Model**:
```python
class HierarchicalClassifier(nn.Module):
    def __init__(self):
        self.encoder = GraphCodeBERT()
        
        # Level 1: Binary
        self.level1_classifier = nn.Linear(768, 2)
        
        # Level 2: Multi-class (only for vulnerable)
        self.level2_classifier = nn.Linear(768, 4)
    
    def forward(self, x):
        features = self.encoder(x)
        
        # First classify safe vs vulnerable
        level1_logits = self.level1_classifier(features)
        
        # If vulnerable, classify type
        if level1_logits.argmax() == 1:  # Vulnerable
            level2_logits = self.level2_classifier(features)
            return level1_logits, level2_logits
        else:
            return level1_logits, None
```

**Training**:
```python
# Joint training with weighted loss
loss = alpha * level1_loss + beta * level2_loss
```

**Æ¯u Ä‘iá»ƒm**:
- âœ… Chia nhá» bÃ i toÃ¡n phá»©c táº¡p
- âœ… CÃ³ thá»ƒ focus vÃ o vulnerable code
- âœ… Interpretable

---

## ğŸ”¥ Recommendation: Approach NÃ o NÃªn Báº¯t Äáº§u?

### **Giai Äoáº¡n 1: Baseline (1-2 tuáº§n)**
â†’ **Binary Classification (#1)**
- Nhanh, Ä‘Æ¡n giáº£n
- Verify dataset quality
- Establish baseline performance

### **Giai Äoáº¡n 2: Improve (2-3 tuáº§n)**
â†’ **Multi-Class Classification (#2)**
- PhÃ¢n loáº¡i chi tiáº¿t hÆ¡n
- So sÃ¡nh vá»›i baseline
- Analyze per-class performance

### **Giai Äoáº¡n 3: Advanced (3-4 tuáº§n)**
â†’ **Graph-based Approach (#4)**
- Táº­n dá»¥ng AST structure
- Potentially best performance
- Publication-worthy

### **Giai Äoáº¡n 4: Research (Optional)**
â†’ **Contrastive Learning (#3)**
- Novel approach
- Useful for code suggestion
- Good for research paper

---

## ğŸ“‹ Implementation Checklist

### Data Preparation
- [ ] Count files per vulnerability type
- [ ] Parse JSON to extract graph structure
- [ ] Split train/val/test (70/15/15)
- [ ] Balance dataset (if needed)
- [ ] Create data loaders

### Model Development
- [ ] Setup GraphCodeBERT
- [ ] Implement preprocessing pipeline
- [ ] Build model architecture
- [ ] Define loss function
- [ ] Setup training loop

### Evaluation
- [ ] Accuracy, Precision, Recall, F1
- [ ] Confusion matrix
- [ ] Per-class metrics
- [ ] Error analysis

### Experimentation
- [ ] Hyperparameter tuning
- [ ] Different learning rates
- [ ] Different architectures
- [ ] Ensemble methods

---

## ğŸ› ï¸ Technical Stack

```python
# Core libraries
- torch >= 2.0
- transformers >= 4.30 (for GraphCodeBERT)
- torch-geometric (for GNN approaches)
- scikit-learn (for metrics)
- pandas (for data handling)
- wandb (for experiment tracking)

# GraphCodeBERT
from transformers import RobertaTokenizer, RobertaModel
tokenizer = RobertaTokenizer.from_pretrained("microsoft/graphcodebert-base")
model = RobertaModel.from_pretrained("microsoft/graphcodebert-base")
```

---

## ğŸ“Š Expected Results

### Binary Classification
- Expected Accuracy: **85-90%**
- Why: Clear difference between vulnerable and safe code

### Multi-Class Classification
- Expected Accuracy: **75-85%**
- Why: Some vulnerability types overlap

### Graph-based Approach
- Expected Accuracy: **88-93%**
- Why: Leverage structural information

---

## ğŸ’¡ Bonus Ideas

### 6ï¸âƒ£ Explainability
- Use attention weights to highlight vulnerable code snippets
- Generate explanations: "Vulnerable because of unsanitized input at line X"

### 7ï¸âƒ£ Code Fix Suggestion
- Train sequence-to-sequence model
- Input: Vulnerable code
- Output: Fixed code
- Based on paired dataset

### 8ï¸âƒ£ Ensemble
- Combine multiple approaches
- Voting: Binary + Multi-class + Graph
- Boost performance by 2-5%

### 9ï¸âƒ£ Active Learning
- Model suggests which code to label next
- Efficient use of labeling effort

### ğŸ”Ÿ Transfer Learning
- Pre-train on larger code corpus
- Fine-tune on vulnerability detection
- Improve generalization
